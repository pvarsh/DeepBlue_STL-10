\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times,cite}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{Assignment 2: Classifying STL-10 with a deep feed-forward convolutional neural net}


\author{
Priyank Bhatia \\
New York University \\
Center for Urban Science + Progress \\
1 MetroTech Center, 19th Floor \\
Brooklyn, NY 11201 \\
\texttt{pb1672@nyu.edu} \\
\AND
Emil Christensen \\
New York University \\
Center for Urban Science + Progress \\
1 MetroTech Center, 19th Floor \\
Brooklyn, NY 11201 \\
\texttt{erc399@nyu.edu} \\
\And
Peter Varshavsky \\
New York University \\
Center for Urban Science + Progress \\
1 MetroTech Center, 19th Floor \\
Brooklyn, NY 11201 \\
\texttt{pv629@nyu.edu} \\
}


% Some example code:

%\begin{center}
%   \url{URLs go here}
%\end{center}

%\section{A section!}
%\subsection{A subsection!}

%\label{sub_1} - label a section
%\ref{sub_1} - reference a labeled section

%\footnote{Sample of a footnote}

% Figures:
% \begin{figure}[h]
% \begin{center}
% \framebox[4.0in]{$\;$}
% \fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
% \end{center}
% \caption{Sample figure caption.}
% \end{figure}

% Tables:
% \begin{table}[t]
% \caption{Sample table title}
% \label{sample-table}
% \begin{center}
% \begin{tabular}{ll}
% \multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
% \\ \hline \\
% Dendrite         &Input terminal \\
% Axon             &Output terminal \\
% Soma             &Cell body (contains cell nucleus) \\
% \end{tabular}
% \end{center}
% \end{table}

% Lists (can be recursive):
% \begin{itemize}
% \item Item 1
% \item Item 2
% \item Item 3
% \end{itemize}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\nipsfinalcopy % Uncomment for camera-ready version


\begin{document}

\maketitle


\begin{abstract}
The abstract paragraph goes here!
\end{abstract}

\section{Data}
\label{data}
Designed to study the use of unlabeled data for image classification, the STL-10 dataset \cite{coates2011analysis} consists of three sets of 96x96 pixel RGB color images: 5000 labeled training images, 8000 labeled test images, and 100000 unlabeled images. Each image belongs to one of 10 categories. In this submission we only utilize the labeled portion of STL-10 and attempt to improve classification quality by image augmentation and depth of network.

\section{Architecture}
\label{arc}
Two versions of a feed-forward convolutional neural net architectures were compared. The first (CP) architecture was an implementation of the baseline model by Christian Puhrsch with one convolutional layer of 23 7x7 pixel learned filters with a step size of 2, ReLU nonlinearity, 2 sq. pixel max pooling with step size 2, 50\% dropout, a 50-node fully connected layer, ReLU, LogSoftMax and, and a negative log likelihood criterion.
The second model (A1) used the same basic architecture but consisted of two convolutional layers of 200 and 400 5x5 pixel filters each, and a 800-neuron fully connected linear layer. Spatial pooling, rectified linear unit nonlinearities and dropout were applied as in the first network.

\section{Preprocessing and augmentation}
\label{preproc}
The original 5000 training images were split into training and validation sets of sizes 4500 and 500. To ameliorate the small training size and improve feature invariance the 4500 training images were cloned twice. The first cloned set was flipped horizontally, and the second was rotated counter-clockwise by 0.35 radians. This yielded an augmented training set of 13500 images. We further attempted to augment the training set using contrast HSV color space adjustments similar to contrast2 in ~\cite{DosovitskiySRB14}, small random translations and rotations, but ran into training convergence issues, possibly due to coding errors. Augmented data were converted to YUV color space. Training images were globally normalized. Validation and test images were globally normalized using training mean and standard deviation. All images were further locally normalized and given a 2-pixel zero padding.

\section{Training Procedure}
\label{train}
Both models were trained with mini batch stochastic gradient descent with batch sizes 1, 8, 32, and 128. Additionally a shorter version of model A1 (two 200-filter convolutional layers, 400-node fully connected layer) was evaluated. Non fully stochastic mini batches improved both runtime and accuracy as suggested in \cite{lecun-98b}. The full A1 architecture yielded the best performance on the validation set with mini batch size 8.  The best-performing model was then retrained on the full 5000-image training set and evaluated on the test set. 
\begin{center}
	\begin{tabular}{ | l | r | r | r | }
		\hline
			& \multicolumn{3}{| c |}{A1 model accuracy} \\ \hline
			& Train   	& Validation 	& Test		\\ \hline
		1   & 75.76\% 	& 52.20\%		&  - 		\\ \hline
		8   & 92.4\% 	& 61.8\%		&  62.55\%	\\ \hline
		32  & 89.81\% 	& 61.6\% 		&  -		\\ \hline
		128 & 63.22\% 	& 54.2\%		&  -		\\ \hline
	\end{tabular}
\end{center}

\section{Results}
\label{res}
\begin{center}
  \begin{tabular}{ | l | l | l | l |}
  \hline
  \multicolumn{4}{| c |}{Model 1 - One convolutional layer} \\ \hline
                           & train error & validation error & test error \\ \hline
  train with validation    & ...         & ...              & ...        \\ \hline
  train without validation & ...         & ...        & ...      \\ \hline
  
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{ | l | l | l | l |}
  \hline
  \multicolumn{4}{| c |}{Model 2 - Two convolutional layers} \\ \hline
                           & train error & validation error & test error \\ \hline
  train with validation    & 87.82\%     & 60.0\%           & 61.69\%    \\ \hline
  train without validation & ...         & N/A        & ...      \\ \hline
  
  \end{tabular}
\end{center}


\bibliography{citations}{}
\bibliographystyle{plain}

\end{document}

